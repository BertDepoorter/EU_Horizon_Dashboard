{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "`Overview`\n",
    "This notebook handles the initial data processing pipeline:\n",
    "- Loading raw data from source files\n",
    "- Performing exploratory data analysis (EDA)\n",
    "- Cleaning and handling missing values\n",
    "- Feature preprocessing and engineering\n",
    "- Exporting processed datasets for modeling\n",
    "\n",
    "`Inputs`\n",
    "- Raw data files from `../data/raw/` \n",
    "\n",
    "`Outputs`\n",
    "- Processed datasets in `../data/processed/`\n",
    "- EDA visualizations in `../reports/figures/`\n",
    "\n",
    "`Dependencies`\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "\n",
    "*Note: This is notebook 1 of the analysis pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "# from src.save_load import save_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the project specific datasets as CSV files. In the follow-up cell, we load the auxiliary dataset containing extra information on the CORDIS-HORIZON projects. This includes\n",
    "- Scientific vocabulary \n",
    "- legal basis documents\n",
    "- organization\n",
    "- project\n",
    "- topics\n",
    "- webItem \n",
    "- webLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset as pandas DataFrame\n",
    "run_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(run_dir)\n",
    "\n",
    "raw_dir = f'{parent_dir}/data/raw'\n",
    "interim_dir = f'{parent_dir}/data/interim'\n",
    "processed_dir = f'{parent_dir}/data/processed'\n",
    "\n",
    "# define file paths to project-specific files\n",
    "data_report_path = f'{raw_dir}/reportSummaries.csv'\n",
    "data_filereport_path = f'{raw_dir}/file_report.csv'\n",
    "data_publications_path = f'{raw_dir}/projectPublications.csv'\n",
    "data_deliverables_path = f'{raw_dir}/projectDeliverables.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'projectID', 'projectAcronym', 'attachment',\n",
       "       'contentUpdateDate', 'rcn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get DataFrame keys\n",
    "data_report = pd.read_csv(data_report_path, delimiter=';')\n",
    "data_report.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>projectID</th>\n",
       "      <th>projectAcronym</th>\n",
       "      <th>attachment</th>\n",
       "      <th>contentUpdateDate</th>\n",
       "      <th>rcn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101066069_PSHORIZON</td>\n",
       "      <td>Periodic Reporting for period 1 - ERASMUS (Ear...</td>\n",
       "      <td>101066069</td>\n",
       "      <td>ERASMUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-17 10:38:00</td>\n",
       "      <td>1267558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101073231_PSHORIZON</td>\n",
       "      <td>Periodic Reporting for period 1 - OncoProTools...</td>\n",
       "      <td>101073231</td>\n",
       "      <td>OncoProTools</td>\n",
       "      <td>/docs/results/horizon/101073/101073231_PS/2024...</td>\n",
       "      <td>2025-03-18 12:31:34</td>\n",
       "      <td>1270628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101068156_PSHORIZON</td>\n",
       "      <td>Periodic Reporting for period 1 - BLISS (Beta-...</td>\n",
       "      <td>101068156</td>\n",
       "      <td>BLISS</td>\n",
       "      <td>/docs/results/horizon/101068/101068156_PS/pict...</td>\n",
       "      <td>2025-03-05 11:47:45</td>\n",
       "      <td>1260626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101072180_PSHORIZON</td>\n",
       "      <td>Periodic Reporting for period 1 - Green2Ice (W...</td>\n",
       "      <td>101072180</td>\n",
       "      <td>Green2Ice</td>\n",
       "      <td>/docs/results/horizon/101072/101072180_PS/2023...</td>\n",
       "      <td>2025-02-14 10:36:27</td>\n",
       "      <td>1252991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101063407_PSHORIZON</td>\n",
       "      <td>Periodic Reporting for period 1 - GHost (His E...</td>\n",
       "      <td>101063407</td>\n",
       "      <td>GHost</td>\n",
       "      <td>/docs/results/horizon/101063/101063407_PS/pa-1...</td>\n",
       "      <td>2025-02-26 17:32:14</td>\n",
       "      <td>1257475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              title  \\\n",
       "0  101066069_PSHORIZON  Periodic Reporting for period 1 - ERASMUS (Ear...   \n",
       "1  101073231_PSHORIZON  Periodic Reporting for period 1 - OncoProTools...   \n",
       "2  101068156_PSHORIZON  Periodic Reporting for period 1 - BLISS (Beta-...   \n",
       "3  101072180_PSHORIZON  Periodic Reporting for period 1 - Green2Ice (W...   \n",
       "4  101063407_PSHORIZON  Periodic Reporting for period 1 - GHost (His E...   \n",
       "\n",
       "   projectID projectAcronym  \\\n",
       "0  101066069        ERASMUS   \n",
       "1  101073231   OncoProTools   \n",
       "2  101068156          BLISS   \n",
       "3  101072180      Green2Ice   \n",
       "4  101063407          GHost   \n",
       "\n",
       "                                          attachment    contentUpdateDate  \\\n",
       "0                                                NaN  2025-03-17 10:38:00   \n",
       "1  /docs/results/horizon/101073/101073231_PS/2024...  2025-03-18 12:31:34   \n",
       "2  /docs/results/horizon/101068/101068156_PS/pict...  2025-03-05 11:47:45   \n",
       "3  /docs/results/horizon/101072/101072180_PS/2023...  2025-02-14 10:36:27   \n",
       "4  /docs/results/horizon/101063/101063407_PS/pa-1...  2025-02-26 17:32:14   \n",
       "\n",
       "       rcn  \n",
       "0  1267558  \n",
       "1  1270628  \n",
       "2  1260626  \n",
       "3  1252991  \n",
       "4  1257475  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "1. we check each column for missing values\n",
    "2. Define decision tree for handling missing values\n",
    "3. Change values algorithmically\n",
    "4. Store update dataframe in interim directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For key id:\n",
      "     0 elements are missing.\n",
      "For key title:\n",
      "     0 elements are missing.\n",
      "For key projectID:\n",
      "     0 elements are missing.\n",
      "For key projectAcronym:\n",
      "     0 elements are missing.\n",
      "For key attachment:\n",
      "     1861 elements are missing.\n",
      "For key contentUpdateDate:\n",
      "     0 elements are missing.\n",
      "For key rcn:\n",
      "     0 elements are missing.\n"
     ]
    }
   ],
   "source": [
    "# look for missing values\n",
    "report_missing = data_report.isnull()\n",
    "\n",
    "# check which columns are missing data\n",
    "for key in data_report:\n",
    "    missing = report_missing[report_missing[key] == True]\n",
    "    print(f'For key {key}:\\n     {len(missing.id)} elements are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are only missing attachments. These attachments refer to some additional documents, mostly png picture.\n",
    "We can handle this in three ways\n",
    "- Look manually for the missing attachments \n",
    "- Ignore this column during analysis\n",
    "- if attachment present: add to dashboard when user wants to inspect a particular project. If not present: leave blank. \n",
    "\n",
    "I recommend using the last approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "\n",
    "# define missng values rule here\n",
    "\n",
    "# change the missing values in dataframe\n",
    "project_reports_interim = data_report\n",
    "# save updated dataframe to data/interim\n",
    "project_reports_interim.to_csv(f'{interim_dir}/reportSummaries_interim.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inspect other report file\n",
    "This CSV file does not contain useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename,status, issue_cause downloadURL, issue_cause accessURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HORIZON Report summaries (individual XML files...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HORIZON Projects,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HORIZON Projects Deliverables,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HORIZON Projects (individual XML files),delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HORIZON Projects Deliverables (individual XML ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HORIZON Report summaries,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HORIZON Publications,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HORIZON Projects Deliverables,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HORIZON Publications,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HORIZON Projects Deliverables,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HORIZON Publications (individual XML files),is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HORIZON Report summaries,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HORIZON Publications,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HORIZON Projects,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HORIZON Report summaries,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HORIZON Projects,delivered,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CORDIS HORIZON organisations' collaboration ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename,status, issue_cause downloadURL, issue_cause accessURL\n",
       "0   HORIZON Report summaries (individual XML files...             \n",
       "1                        HORIZON Projects,delivered,,             \n",
       "2           HORIZON Projects Deliverables,delivered,,             \n",
       "3   HORIZON Projects (individual XML files),delive...             \n",
       "4   HORIZON Projects Deliverables (individual XML ...             \n",
       "5                HORIZON Report summaries,delivered,,             \n",
       "6                    HORIZON Publications,delivered,,             \n",
       "7           HORIZON Projects Deliverables,delivered,,             \n",
       "8                    HORIZON Publications,delivered,,             \n",
       "9           HORIZON Projects Deliverables,delivered,,             \n",
       "10  HORIZON Publications (individual XML files),is...             \n",
       "11               HORIZON Report summaries,delivered,,             \n",
       "12                   HORIZON Publications,delivered,,             \n",
       "13                       HORIZON Projects,delivered,,             \n",
       "14               HORIZON Report summaries,delivered,,             \n",
       "15                       HORIZON Projects,delivered,,             \n",
       "16  CORDIS HORIZON organisations' collaboration ne...             "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filereport = pd.read_csv(data_filereport_path, delimiter=';')\n",
    "data_filereport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 10 fields in line 1416, saw 11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33352\\1955738666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Inspect Dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_deliverables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_deliverables_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_deliverables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suley\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 10 fields in line 1416, saw 11\n"
     ]
    }
   ],
   "source": [
    "# Inspect Dataframe\n",
    "data_deliverables = pd.read_csv(data_deliverables_path, delimiter=';')\n",
    "data_deliverables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have changed the following lines to enable opening the file with pandas:\n",
    "- 1412: something wrong in the deliverable description\n",
    "- 1412: wrong use of delimiter\n",
    "- 6677: wrong use of quotation marks\n",
    "- 6678: wrong use of quotation marks\n",
    "- 8812: use of delimiter inside string\n",
    "- 8826: use of delimiter inside string\n",
    "- 9360: use of delimiter inside string\n",
    "- 9524: use of delimiter inside string\n",
    "- 10128: use of delimiter inside string\n",
    "- 13108: use of delimiter inside string\n",
    "- 19931: use of delimiter inside string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Missing values\n",
    "Here we handle the missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for missing values\n",
    "deliverables_missing = data_deliverables.isnull()\n",
    "\n",
    "# check which columns are missing data\n",
    "for key in deliverables_missing.keys():\n",
    "    missing = deliverables_missing[deliverables_missing[key] == True]\n",
    "    print(f'For key {key}:\\n     {len(missing.id)} elements are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are missing elements in the following columns:\n",
    "- deliverableType\n",
    "    - option 1: change to `'other'`\n",
    "    - option 2: look up individual titles and add manually\n",
    "- description\n",
    "    - option 1: add empty string\n",
    "    - Inspect manually to gain more insight what they exactly represent\n",
    "        - Update: all the titles related to the projects are quite related. I suggest we copy title values into the description column.\n",
    "- url\n",
    "    - 1 missing url. Add the url to the main page of this project (SELFY, id = 101069748_16_DELIVHORIZON) instead of link to deliverable?\n",
    "- rcn\n",
    "    - 1 rcn is missing. \n",
    "    - Looked this number up in publication list based on the projectAcronym = `'GeneBEcon'`. There the rcn number is gives as `1077637.0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change unknown deliverable types to other\n",
    "data_deliverables['deliverableType'] = data_deliverables['deliverableType'].fillna('Other') \n",
    "\n",
    "# change empty descriptions to title of that particular row\n",
    "data_deliverables['description'] = data_deliverables['description'].fillna(data_deliverables['title'])\n",
    "\n",
    "# change missing url to homepage of the particular project\n",
    "data_deliverables['url'] = data_deliverables['url'].fillna('https://selfy-project.eu/')\n",
    "\n",
    "# add missing rcn number\n",
    "data_deliverables['rcn'] = data_deliverables['rcn'].fillna(1077637.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether filling executed correctly\n",
    "data_deliverables[deliverables_missing.deliverableType == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated dataframe to data/interim\n",
    "data_deliverables.to_csv(f'{interim_dir}/projectdeliverables_interim.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inspect Publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 16 fields in line 7588, saw 17\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inspect Dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_publications \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_publications_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m data_publications\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 16 fields in line 7588, saw 17\n"
     ]
    }
   ],
   "source": [
    "# Inspect Dataframe\n",
    "data_publications = pd.read_csv(data_publications_path, delimiter=';')\n",
    "data_publications.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some entries in the publications CSV have been changed by hand, in order to allow loading them:\n",
    "- 7588\n",
    "- 7748\n",
    "\n",
    "Both are from the same conference. Problem: switched the order of the columns and add one additional empty column causing pandas loader to crash. \n",
    "\n",
    "Next problems:\n",
    "- 12036: wrong notation of authors names + use of ; delimiter inside string.\n",
    "- 12043: start authors string with four \" + use ; to separate names.\n",
    "- 12099: same problem as stated above\n",
    "- 12110: same problem\n",
    "- 12115: same problem\n",
    "- 12270: same problem\n",
    "- 18735: same problem\n",
    "- 24019: same problem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_publications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Missin values\n",
    "Here we inspect the missing data in this file, and outline how we are goiing to treat these missing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for missing values\n",
    "publications_missing = data_publications.isnull()\n",
    "\n",
    "# check which columns are missing data\n",
    "for key in publications_missing.keys():\n",
    "    missing = publications_missing[publications_missing[key] == True]\n",
    "    if len(missing.id) > 0:\n",
    "        print(f'For key {key}:\\n     {len(missing.id)} elements are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite some missing data in this file. Let us go through each line individually.\n",
    "- authors:\n",
    "    - This sucks. Would have been very nice to decompose author strings into single authors and make the connections\n",
    "    - How to treat this: look into the article title string to check whether this one contains more author infromation\n",
    "- journalTitle:\n",
    "    - chack in the publication title. Sometimes there one has just copy-pasted the whole article reference\n",
    "- journalNumber:\n",
    "    - Not the most relevant parameter in my opinion. Just make all NaN zeros\n",
    "- publishedYear:\n",
    "    - Manually look this up\n",
    "- publishedPages:\n",
    "    - Not the most relevant parameter in my opinion. Just make all NaN zeros\n",
    "- issn:\n",
    "    - Not the most relevant parameter in my opinion. Just make all NaN zeros\n",
    "- isbn:\n",
    "    - Not the most relevant parameter in my opinion. Just make all NaN zeros\n",
    "- doi:\n",
    "    - Fuck this, just pass about:blank as url. \n",
    "- rcn:\n",
    "    - Manually adjust this one. \n",
    "        - Update: this entry was missing an entry for authors, all following field shifted 1 column to the left. Manually fixed this one. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_publications.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing rcn. \n",
    "data_publications[publications_missing.rcn == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill some gaps in the data structure\n",
    "data_publications['isbn'] = data_publications['isbn'].fillna('0000-0000')\n",
    "data_publications['issn'] = data_publications['issn'].fillna('0000-0000')\n",
    "data_publications['publishedPages'] = data_publications['publishedPages'].fillna(0)\n",
    "data_publications['doi'] = data_publications['doi'].fillna('about:blank')\n",
    "data_publications['journalTitle'] = data_publications['journalTitle'].fillna('Miscalleneous')\n",
    "data_publications['journalNumber'] = data_publications['journalNumber'].fillna(0)\n",
    "data_publications['authors'] = data_publications['authors'].fillna('sine nome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data_publications again\n",
    "publications_missing = data_publications.isnull()\n",
    "\n",
    "# check which columns are missing data\n",
    "for key in publications_missing.keys():\n",
    "    missing = publications_missing[publications_missing[key] == True]\n",
    "    if len(missing.id) > 0:\n",
    "        print(f'For key {key}:\\n     {len(missing.id)} elements are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are no empty entries left. We store the completed dataset in the interim folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to intermediate\n",
    "data_publications.to_csv(f'{interim_dir}/projectPublications_interim.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inspect CORDIS-HORIZON projects data files\n",
    "This is the folder containing some more datasets on the different projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file paths\n",
    "CORDIS_framework_docs_dir = f'{raw_dir}/cordis-HORIZONprojects-csv'\n",
    "\n",
    "SciVoc_path = f'{CORDIS_framework_docs_dir}/euroSciVoc.csv'\n",
    "legalBasis_path = f'{CORDIS_framework_docs_dir}/legalBasis.csv'\n",
    "organization_path = f'{CORDIS_framework_docs_dir}/organization.csv'\n",
    "project_path = f'{CORDIS_framework_docs_dir}/project.csv'\n",
    "topics_path = f'{CORDIS_framework_docs_dir}/topics.csv'\n",
    "webItems_path = f'{CORDIS_framework_docs_dir}/webItem.csv'\n",
    "webLink_path = f'{CORDIS_framework_docs_dir}/webLink.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some informative files\n",
    "\n",
    "# load datasets\n",
    "read_csv_options = {\n",
    "    \"delimiter\": \";\",\n",
    "    \"quotechar\": '\"',\n",
    "    \"escapechar\": \"\\\\\",\n",
    "    'doublequote': False,\n",
    "    # \"on_bad_lines\": \"skip\",   # we skip lines that do not import properly for now\n",
    "    \"engine\": \"python\"  # 'python' engine handles complex parsing better\n",
    "}\n",
    "\n",
    "\n",
    "sci_voc_df = pd.read_csv(SciVoc_path, **read_csv_options)\n",
    "legal_basis_df = pd.read_csv(legalBasis_path, **read_csv_options)\n",
    "organization_df = pd.read_csv(organization_path, delimiter=';')\n",
    "topics_df = pd.read_csv(topics_path, **read_csv_options)\n",
    "web_items_df = pd.read_csv(webItems_path, **read_csv_options)\n",
    "web_link_df = pd.read_csv(webLink_path, **read_csv_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15736\n"
     ]
    }
   ],
   "source": [
    "read_csv_options['on_bad_lines'] = 'skip'\n",
    "try:\n",
    "    project_df = pd.read_csv(project_path, **read_csv_options)\n",
    "    print(len(project_df.id))\n",
    "except pd.errors.ParserError as e:\n",
    "    print(\"Parsing error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15863 - 15737 = 126 field which could not be read. Let us inspect those lines further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acronym</th>\n",
       "      <th>status</th>\n",
       "      <th>title</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>totalCost</th>\n",
       "      <th>ecMaxContribution</th>\n",
       "      <th>legalBasis</th>\n",
       "      <th>topics</th>\n",
       "      <th>ecSignatureDate</th>\n",
       "      <th>frameworkProgramme</th>\n",
       "      <th>masterCall</th>\n",
       "      <th>subCall</th>\n",
       "      <th>fundingScheme</th>\n",
       "      <th>nature</th>\n",
       "      <th>objective</th>\n",
       "      <th>contentUpdateDate</th>\n",
       "      <th>rcn</th>\n",
       "      <th>grantDoi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101159220</td>\n",
       "      <td>PvSeroRDT</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>A point-of-care serological rapid diagnostic t...</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>2030-01-31</td>\n",
       "      <td>4062396,23</td>\n",
       "      <td>4062396,23</td>\n",
       "      <td>HORIZON.2.1</td>\n",
       "      <td>HORIZON-JU-GH-EDCTP3-2023-02-02-two-stage</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-JU-GH-EDCTP3-2023-02-two-stage</td>\n",
       "      <td>HORIZON-JU-GH-EDCTP3-2023-02-two-stage</td>\n",
       "      <td>HORIZON-JU-RIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plasmodium vivax is considered the most diffic...</td>\n",
       "      <td>2024-12-24 11:18:48</td>\n",
       "      <td>268210</td>\n",
       "      <td>10.3030/101159220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101096150</td>\n",
       "      <td>BIOBoost</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Boosting innovation agencies for bioeconomy va...</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>500000</td>\n",
       "      <td>HORIZON.3.2</td>\n",
       "      <td>HORIZON-EIE-2022-CONNECT-01-01</td>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-EIE-2022-CONNECT-01</td>\n",
       "      <td>HORIZON-EIE-2022-CONNECT-01</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The overall objectives of the BIOBoost project...</td>\n",
       "      <td>2022-12-01 14:09:06</td>\n",
       "      <td>243343</td>\n",
       "      <td>10.3030/101096150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101093997</td>\n",
       "      <td>GlycanTrigger</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>GLYCANS AS MASTER TRIGGERS OF HEALTH TO INTEST...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2028-12-31</td>\n",
       "      <td>6771571</td>\n",
       "      <td>6771571</td>\n",
       "      <td>HORIZON.2.1</td>\n",
       "      <td>HORIZON-HLTH-2022-STAYHLTH-02-01</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-HLTH-2022-STAYHLTH-02</td>\n",
       "      <td>HORIZON-HLTH-2022-STAYHLTH-02</td>\n",
       "      <td>HORIZON-RIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chronic inflammation underlies several disease...</td>\n",
       "      <td>2022-12-11 19:02:29</td>\n",
       "      <td>243439</td>\n",
       "      <td>10.3030/101093997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101126531</td>\n",
       "      <td>CHIKVAX_CHIM</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Late-stage clinical development of Chikungunya...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2028-11-30</td>\n",
       "      <td>100000000</td>\n",
       "      <td>70000000</td>\n",
       "      <td>HORIZON.2.1</td>\n",
       "      <td>HORIZON-HLTH-2022-CEPI-15-01-IBA</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-HLTH-2022-CEPI-15-IBA</td>\n",
       "      <td>HORIZON-HLTH-2022-CEPI-15-IBA</td>\n",
       "      <td>HORIZON-COFUND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Framework Partnership Agreement (FPA) betwee...</td>\n",
       "      <td>2023-09-19 19:01:01</td>\n",
       "      <td>256925</td>\n",
       "      <td>10.3030/101126531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101113979</td>\n",
       "      <td>The Oater</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>The Oater develops a compact machine for hyper...</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>75000</td>\n",
       "      <td>HORIZON.3.2</td>\n",
       "      <td>HORIZON-EIE-2022-SCALEUP-02-02</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-EIE-2022-SCALEUP-02</td>\n",
       "      <td>HORIZON-EIE-2022-SCALEUP-02</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Oater is a female-founded food tech start-...</td>\n",
       "      <td>2023-07-11 15:45:49</td>\n",
       "      <td>253030</td>\n",
       "      <td>10.3030/101113979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>101052410</td>\n",
       "      <td>EUCYS2022</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>EUCYS Leiden2022</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2000000</td>\n",
       "      <td>2000000</td>\n",
       "      <td>HORIZON.4.2</td>\n",
       "      <td>HORIZON-WIDERA-2021-EUCYS-IBA</td>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-WIDERA-2021-EUCYS-IBA</td>\n",
       "      <td>HORIZON-WIDERA-2021-EUCYS-IBA</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The main objective of this Proposal is the org...</td>\n",
       "      <td>2023-03-10 20:23:58</td>\n",
       "      <td>241771</td>\n",
       "      <td>10.3030/101052410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15732</th>\n",
       "      <td>101124648</td>\n",
       "      <td>RESAVER_2023</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Support to Retirement Savings Vehicle for Euro...</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>2026-08-31</td>\n",
       "      <td>2499638,25</td>\n",
       "      <td>2499638,25</td>\n",
       "      <td>HORIZON.4.2</td>\n",
       "      <td>HORIZON-WIDERA-2023-RESAVER-IBA</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-WIDERA-2023-RESAVER-IBA</td>\n",
       "      <td>HORIZON-WIDERA-2023-RESAVER-IBA</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The overall aim of the RESAVER Pension Fund as...</td>\n",
       "      <td>2023-10-13 14:43:57</td>\n",
       "      <td>257324</td>\n",
       "      <td>10.3030/101124648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>101052247</td>\n",
       "      <td>Leiden2022-ECS-ESOF</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>European City of Science and EuroScience Open ...</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>3709149,25</td>\n",
       "      <td>2000000</td>\n",
       "      <td>HORIZON.4.2</td>\n",
       "      <td>HORIZON-WIDERA-2021-ESOF-IBA</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-WIDERA-2021-ESOF-IBA</td>\n",
       "      <td>HORIZON-WIDERA-2021-ESOF-IBA</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The main objective of this proposal is the org...</td>\n",
       "      <td>2022-09-14 19:17:24</td>\n",
       "      <td>241770</td>\n",
       "      <td>10.3030/101052247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15734</th>\n",
       "      <td>101172981</td>\n",
       "      <td>EUCYS2024</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>European Union Contest for Young Scientists (E...</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>999500</td>\n",
       "      <td>999500</td>\n",
       "      <td>HORIZON.4.2</td>\n",
       "      <td>HORIZON-WIDERA-2024-EUCYS-IBA</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-WIDERA-2024-EUCYS-IBA</td>\n",
       "      <td>HORIZON-WIDERA-2024-EUCYS-IBA</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This proposal concerns the organization of the...</td>\n",
       "      <td>2024-04-22 17:56:03</td>\n",
       "      <td>262788</td>\n",
       "      <td>10.3030/101172981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15735</th>\n",
       "      <td>101131799</td>\n",
       "      <td>CO-VALUE</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Citizen-Oriented Valorisation for Advancement,...</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2026-12-31</td>\n",
       "      <td>1046625</td>\n",
       "      <td>1046625</td>\n",
       "      <td>HORIZON.4.2</td>\n",
       "      <td>HORIZON-WIDERA-2023-ERA-01-03</td>\n",
       "      <td>2023-10-05</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-WIDERA-2023-ERA-01</td>\n",
       "      <td>HORIZON-WIDERA-2023-ERA-01</td>\n",
       "      <td>HORIZON-CSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The overall objective of CO-VALUE is to boost ...</td>\n",
       "      <td>2023-11-08 18:09:10</td>\n",
       "      <td>257695</td>\n",
       "      <td>10.3030/101131799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15736 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id              acronym  status  \\\n",
       "0      101159220            PvSeroRDT  SIGNED   \n",
       "1      101096150             BIOBoost  SIGNED   \n",
       "2      101093997        GlycanTrigger  SIGNED   \n",
       "3      101126531         CHIKVAX_CHIM  SIGNED   \n",
       "4      101113979            The Oater  CLOSED   \n",
       "...          ...                  ...     ...   \n",
       "15731  101052410            EUCYS2022  CLOSED   \n",
       "15732  101124648         RESAVER_2023  SIGNED   \n",
       "15733  101052247  Leiden2022-ECS-ESOF  CLOSED   \n",
       "15734  101172981            EUCYS2024  SIGNED   \n",
       "15735  101131799             CO-VALUE  SIGNED   \n",
       "\n",
       "                                                   title   startDate  \\\n",
       "0      A point-of-care serological rapid diagnostic t...  2025-02-01   \n",
       "1      Boosting innovation agencies for bioeconomy va...  2023-02-01   \n",
       "2      GLYCANS AS MASTER TRIGGERS OF HEALTH TO INTEST...  2023-01-01   \n",
       "3      Late-stage clinical development of Chikungunya...  2023-06-01   \n",
       "4      The Oater develops a compact machine for hyper...  2023-07-01   \n",
       "...                                                  ...         ...   \n",
       "15731                                   EUCYS Leiden2022  2021-09-01   \n",
       "15732  Support to Retirement Savings Vehicle for Euro...  2023-09-01   \n",
       "15733  European City of Science and EuroScience Open ...  2021-08-01   \n",
       "15734  European Union Contest for Young Scientists (E...  2024-02-01   \n",
       "15735  Citizen-Oriented Valorisation for Advancement,...  2024-01-01   \n",
       "\n",
       "          endDate   totalCost ecMaxContribution   legalBasis  \\\n",
       "0      2030-01-31  4062396,23        4062396,23  HORIZON.2.1   \n",
       "1      2025-01-31           0            500000  HORIZON.3.2   \n",
       "2      2028-12-31     6771571           6771571  HORIZON.2.1   \n",
       "3      2028-11-30   100000000          70000000  HORIZON.2.1   \n",
       "4      2023-12-31           0             75000  HORIZON.3.2   \n",
       "...           ...         ...               ...          ...   \n",
       "15731  2023-02-28     2000000           2000000  HORIZON.4.2   \n",
       "15732  2026-08-31  2499638,25        2499638,25  HORIZON.4.2   \n",
       "15733  2023-03-31  3709149,25           2000000  HORIZON.4.2   \n",
       "15734  2025-02-28      999500            999500  HORIZON.4.2   \n",
       "15735  2026-12-31     1046625           1046625  HORIZON.4.2   \n",
       "\n",
       "                                          topics ecSignatureDate  \\\n",
       "0      HORIZON-JU-GH-EDCTP3-2023-02-02-two-stage      2024-12-09   \n",
       "1                 HORIZON-EIE-2022-CONNECT-01-01      2022-11-25   \n",
       "2               HORIZON-HLTH-2022-STAYHLTH-02-01      2022-12-05   \n",
       "3               HORIZON-HLTH-2022-CEPI-15-01-IBA      2023-06-15   \n",
       "4                 HORIZON-EIE-2022-SCALEUP-02-02      2023-06-05   \n",
       "...                                          ...             ...   \n",
       "15731              HORIZON-WIDERA-2021-EUCYS-IBA      2022-02-07   \n",
       "15732            HORIZON-WIDERA-2023-RESAVER-IBA      2023-07-10   \n",
       "15733               HORIZON-WIDERA-2021-ESOF-IBA      2021-12-13   \n",
       "15734              HORIZON-WIDERA-2024-EUCYS-IBA      2024-04-15   \n",
       "15735              HORIZON-WIDERA-2023-ERA-01-03      2023-10-05   \n",
       "\n",
       "      frameworkProgramme                              masterCall  \\\n",
       "0                HORIZON  HORIZON-JU-GH-EDCTP3-2023-02-two-stage   \n",
       "1                HORIZON             HORIZON-EIE-2022-CONNECT-01   \n",
       "2                HORIZON           HORIZON-HLTH-2022-STAYHLTH-02   \n",
       "3                HORIZON           HORIZON-HLTH-2022-CEPI-15-IBA   \n",
       "4                HORIZON             HORIZON-EIE-2022-SCALEUP-02   \n",
       "...                  ...                                     ...   \n",
       "15731            HORIZON           HORIZON-WIDERA-2021-EUCYS-IBA   \n",
       "15732            HORIZON         HORIZON-WIDERA-2023-RESAVER-IBA   \n",
       "15733            HORIZON            HORIZON-WIDERA-2021-ESOF-IBA   \n",
       "15734            HORIZON           HORIZON-WIDERA-2024-EUCYS-IBA   \n",
       "15735            HORIZON              HORIZON-WIDERA-2023-ERA-01   \n",
       "\n",
       "                                      subCall   fundingScheme  nature  \\\n",
       "0      HORIZON-JU-GH-EDCTP3-2023-02-two-stage  HORIZON-JU-RIA     NaN   \n",
       "1                 HORIZON-EIE-2022-CONNECT-01     HORIZON-CSA     NaN   \n",
       "2               HORIZON-HLTH-2022-STAYHLTH-02     HORIZON-RIA     NaN   \n",
       "3               HORIZON-HLTH-2022-CEPI-15-IBA  HORIZON-COFUND     NaN   \n",
       "4                 HORIZON-EIE-2022-SCALEUP-02     HORIZON-CSA     NaN   \n",
       "...                                       ...             ...     ...   \n",
       "15731           HORIZON-WIDERA-2021-EUCYS-IBA     HORIZON-CSA     NaN   \n",
       "15732         HORIZON-WIDERA-2023-RESAVER-IBA     HORIZON-CSA     NaN   \n",
       "15733            HORIZON-WIDERA-2021-ESOF-IBA     HORIZON-CSA     NaN   \n",
       "15734           HORIZON-WIDERA-2024-EUCYS-IBA     HORIZON-CSA     NaN   \n",
       "15735              HORIZON-WIDERA-2023-ERA-01     HORIZON-CSA     NaN   \n",
       "\n",
       "                                               objective    contentUpdateDate  \\\n",
       "0      Plasmodium vivax is considered the most diffic...  2024-12-24 11:18:48   \n",
       "1      The overall objectives of the BIOBoost project...  2022-12-01 14:09:06   \n",
       "2      Chronic inflammation underlies several disease...  2022-12-11 19:02:29   \n",
       "3      A Framework Partnership Agreement (FPA) betwee...  2023-09-19 19:01:01   \n",
       "4      The Oater is a female-founded food tech start-...  2023-07-11 15:45:49   \n",
       "...                                                  ...                  ...   \n",
       "15731  The main objective of this Proposal is the org...  2023-03-10 20:23:58   \n",
       "15732  The overall aim of the RESAVER Pension Fund as...  2023-10-13 14:43:57   \n",
       "15733  The main objective of this proposal is the org...  2022-09-14 19:17:24   \n",
       "15734  This proposal concerns the organization of the...  2024-04-22 17:56:03   \n",
       "15735  The overall objective of CO-VALUE is to boost ...  2023-11-08 18:09:10   \n",
       "\n",
       "          rcn           grantDoi  \n",
       "0      268210  10.3030/101159220  \n",
       "1      243343  10.3030/101096150  \n",
       "2      243439  10.3030/101093997  \n",
       "3      256925  10.3030/101126531  \n",
       "4      253030  10.3030/101113979  \n",
       "...       ...                ...  \n",
       "15731  241771  10.3030/101052410  \n",
       "15732  257324  10.3030/101124648  \n",
       "15733  241770  10.3030/101052247  \n",
       "15734  262788  10.3030/101172981  \n",
       "15735  257695  10.3030/101131799  \n",
       "\n",
       "[15736 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect organization data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set or correct country values\n",
    "organization_df.loc[organization_df['city']=='Windhoek', 'country']='NA' # NA was probably interpreted as NaN, can also be fixed using keep_default_na=True when loading data\n",
    "organization_df.loc[organization_df['city']=='WINDHOEK', 'country']='NA'\n",
    "organization_df.loc[organization_df['city']=='Crawley', 'country']='UK'\n",
    "organization_df.loc[organization_df['name']=='CEREGE', 'country']='FR'\n",
    "organization_df.loc[organization_df['name']=='Purdue University', 'country']='US'\n",
    "organization_df.loc[organization_df['name']=='Rijk Zwaan', 'country']='NL'\n",
    "\n",
    "# make data numeric where necessary\n",
    "organization_df['totalCost'] = pd.to_numeric(organization_df['totalCost'].str.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For key projectID:\n",
      "     0 elements are missing.\n",
      "For key projectAcronym:\n",
      "     0 elements are missing.\n",
      "For key organisationID:\n",
      "     0 elements are missing.\n",
      "For key vatNumber:\n",
      "     15490 elements are missing.\n",
      "For key name:\n",
      "     0 elements are missing.\n",
      "For key shortName:\n",
      "     25689 elements are missing.\n",
      "For key SME:\n",
      "     263 elements are missing.\n",
      "For key activityType:\n",
      "     23 elements are missing.\n",
      "For key street:\n",
      "     305 elements are missing.\n",
      "For key postCode:\n",
      "     786 elements are missing.\n",
      "For key city:\n",
      "     263 elements are missing.\n",
      "For key country:\n",
      "     0 elements are missing.\n",
      "For key nutsCode:\n",
      "     278 elements are missing.\n",
      "For key geolocation:\n",
      "     673 elements are missing.\n",
      "For key organizationURL:\n",
      "     39135 elements are missing.\n",
      "For key contactForm:\n",
      "     0 elements are missing.\n",
      "For key contentUpdateDate:\n",
      "     0 elements are missing.\n",
      "For key rcn:\n",
      "     0 elements are missing.\n",
      "For key order:\n",
      "     0 elements are missing.\n",
      "For key role:\n",
      "     0 elements are missing.\n",
      "For key ecContribution:\n",
      "     15840 elements are missing.\n",
      "For key netEcContribution:\n",
      "     23 elements are missing.\n",
      "For key totalCost:\n",
      "     599 elements are missing.\n",
      "For key endOfParticipation:\n",
      "     0 elements are missing.\n",
      "For key active:\n",
      "     101153 elements are missing.\n"
     ]
    }
   ],
   "source": [
    "# look for missing values\n",
    "org_missing = organization_df.isnull()\n",
    "\n",
    "# check which columns are missing data\n",
    "for key in organization_df:\n",
    "    missing = org_missing[org_missing[key] == True]\n",
    "    print(f'For key {key}:\\n     {len(missing.index)} elements are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quite some missing values, but most of them i dont think we will need anyways\n",
    "\n",
    "- all entries with role=\"associatedPartner\" have NaN values in the column 'ecContribution' and sometimes in 'netEcContribution' and 'totalCost'. These will be set to 0.\n",
    "- 'geolocation' has missing values that would be useful to have for visualization on a map. could be (approximately) added by looking at the city or address, but not sure if worth the effort\n",
    "-  'activityType' can be added manually for the 23 missing values if necessary, but maybe they're undefined for a reason\n",
    "-  all others i don't think are very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the best metric to quantify the funding will be 'netEcContribution' (not 'EcContribution' or 'totalCost'), although i don't know exactly what the definitions of these are. Note that 'totalCost' is often 0 when the contribution is not, which is probably wrong and they just didn't enter complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nans with 0 in funding metrics\n",
    "organization_df[['ecContribution', 'netEcContribution', 'totalCost']] = organization_df[['ecContribution', 'netEcContribution', 'totalCost']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "organization_df.to_csv(f'{interim_dir}/organization_interim.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct functions to access cleaned data\n",
    "\n",
    "We now define some functions that allow easy access to all aspects of different projects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge datasets into one object\n",
    "- Standardize column names => they are compatible\n",
    "- Create function that allow access to project-specific data:\n",
    "    - function argument: project name / acronym / identifier\n",
    "    - function output: data class with project information as attributes\n",
    "    - Or: approach this from a class init perspective\n",
    "\n",
    "Find some way to pass load datasets\n",
    "apply class on this, without having to load the full dataset each time we initialize the class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to load datasets\n",
    "\n",
    "class CORDIS_data():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize class: load data from the CSV files\n",
    "\n",
    "        set some global variables that we \n",
    "\n",
    "        '''\n",
    "\n",
    "        self.data_report = pd.read_csv(f'{interim_dir}/projectdeliverables_interim.csv', delimiter=';')\n",
    "        self.data_deliverables = pd.read_csv(f'{interim_dir}/projectdeliverables_interim.csv', delimiter=';')\n",
    "\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def list_of_acronyms(self):\n",
    "        '''\n",
    "        This function prints out a dataframe \n",
    "        '''\n",
    "        pass\n",
    "\n",
    "class Project_data(CORDIS_data):\n",
    "    ''' \n",
    "    This class inherits all the attributes from the class CORDIS_data, including the loaded datasets. \n",
    "    Intended use case: \n",
    "        set some new variables related to a project:\n",
    "            - number of deliverables\n",
    "            - deliverable_types\n",
    "            - number of publications\n",
    "            - publication types\n",
    "            - ... (whatever might be useful later on in the project)\n",
    "    '''\n",
    "    \n",
    "    def project(self, id=None, acronym=None):\n",
    "        '''\n",
    "        class to access all information related to a certain project:\n",
    "        create some a\n",
    "\n",
    "        '''\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store post-processed and feature enriched datasets here\n",
    "\n",
    "data_full.to_csv(f'{processed_dir}/CORDIS_enriched.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
